{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from /scratchx/mcarenso/tempest/OBS_Winter_lowRes_Tropics/var_id_days_i_t.json\n",
      "Found grid attributes file , so loading /scratchx/mcarenso/tempest/OBS_Winter_lowRes_Tropics/grid_attributes.pkl instead of computing\n",
      "Warning: ecCodes 2.21.0 or higher is recommended. You are running version 2.16.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Grid' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 226\u001b[0m\n\u001b[1;32m    224\u001b[0m cs \u001b[38;5;241m=\u001b[39m casestudy\u001b[38;5;241m.\u001b[39mCaseStudy(hdlr, overwrite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m ,verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    225\u001b[0m gr \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mGrid(cs, fast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, overwrite\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, verbose_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 226\u001b[0m st \u001b[38;5;241m=\u001b[39m \u001b[43mstorm_tracker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStormTracker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_var_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMCS_label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_storms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m jd \u001b[38;5;241m=\u001b[39m joint_distrib\u001b[38;5;241m.\u001b[39mJointDistribution(gr, \u001b[38;5;28;01mNone\u001b[39;00m, var_id_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_unweighted_Prec\u001b[39m\u001b[38;5;124m\"\u001b[39m, var_id_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcond_alpha_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39malpha\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_Prec\u001b[39m\u001b[38;5;124m\"\u001b[39m, nbpd \u001b[38;5;241m=\u001b[39m nbpd,  nd\u001b[38;5;241m=\u001b[39mnd, overwrite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, dist_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    228\u001b[0m jd_ocean \u001b[38;5;241m=\u001b[39m joint_distrib\u001b[38;5;241m.\u001b[39mJointDistribution(gr, \u001b[38;5;28;01mNone\u001b[39;00m, var_id_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_unweighted_Prec\u001b[39m\u001b[38;5;124m\"\u001b[39m, var_id_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcond_alpha_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39malpha\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_Prec\u001b[39m\u001b[38;5;124m\"\u001b[39m, nbpd \u001b[38;5;241m=\u001b[39m nbpd,  nd\u001b[38;5;241m=\u001b[39mnd, overwrite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, dist_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mocean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/code/tempest/tempest/storm_tracker.py:57\u001b[0m, in \u001b[0;36mStormTracker.__init__\u001b[0;34m(self, casestudy, label_var_id, overwrite_storms, overwrite, verbose)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose : \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading storms...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m :\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds_storms, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_storms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_storms_tracking\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverwrite_storms\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#, self.label_storms, self.dict_i_storms_by_label\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m : \n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds_storms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_storms_tracking_from_netcdf()\n",
      "File \u001b[0;32m~/code/tempest/tempest/storm_tracker.py:106\u001b[0m, in \u001b[0;36mStormTracker.load_storms_tracking\u001b[0;34m(self, overwrite)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_storms_tracking\u001b[39m(\u001b[38;5;28mself\u001b[39m, overwrite):\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m## Make it a netcdf so that we don't struggle with loading it anymore\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     dir_out \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDIR_DATA_OUT\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcasestudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m)\n\u001b[1;32m    107\u001b[0m     file_storms \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_out, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorms_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_var_id\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.nc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    108\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMODEL\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Grid' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # Seaborn enhances the aesthetics of matplotlib plots\n",
    "import matplotlib.patheffects as path_effects\n",
    "from matplotlib.patches import Polygon as MplPolygon\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import logging\n",
    "from skimage import measure # pylance: disable=import-error \n",
    "\n",
    "from scipy.optimize import minimize\n",
    "import plotly.graph_objects as go\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "from tempest import casestudy\n",
    "from tempest import grid\n",
    "from tempest import storm_tracker\n",
    "from tempest import joint_distrib\n",
    "from tempest import handler\n",
    "from tempest.plots.hist import simple_hist\n",
    "\n",
    "alpha = \"75\" #compare to article this is 100(1-alpha) \n",
    "nbpd = 20 # maybe trying with 40 once the legends are added\n",
    "nd = 4\n",
    "same_rank_bool = True # if False then the jdist ranks are computed for ocean and land, rather than for both\n",
    "\n",
    "fig_path = f\"/scratchx/mcarenso/tempest/figures/sigma_ratios_land_ocean_nd_{nd}_nbpd_{nbpd}_alpha_{alpha}_same_rank_{str(same_rank_bool)}.png\"\n",
    "\n",
    "\n",
    "def find_plot_contour(self, ax_show , N_branch=80, offset_low = 1, offset_up=1, color = 'k', lstyle = '--', model_name = None):\n",
    "    Z = self.norm_density.T\n",
    "    # -- Branches\n",
    "    Z_contour = np.copy(Z)\n",
    "    # Z_contour[18:, 18:] = 1 ## this number actually depends on nd and nbpd and the general shape of the Y \n",
    "    cont = measure.find_contours(Z_contour, 1)\n",
    "    N = N_branch\n",
    "    # fit\n",
    "    popt_1, x_1, y_1, popt_2, x_2, y_2, func = self._fit_branches(cont,N, offset_low, offset_up)\n",
    "    x_branch_2 = y_branch_1 = np.linspace(5,N_branch,N_branch)\n",
    "    y_branch_2 = func(x_branch_2,*popt_2)\n",
    "    x_branch_1 = func(y_branch_1,*popt_1)\n",
    "\n",
    "    # Create line strings for intersection\n",
    "    curve1 = LineString(np.column_stack((x_branch_1, y_branch_1)))\n",
    "    curve2 = LineString(np.column_stack((x_branch_2, y_branch_2)))\n",
    "    \n",
    "    if ax_show is not False : \n",
    "        # show branches\n",
    "        ax_show.plot(x_branch_1,y_branch_1, color = color, linestyle = lstyle, linewidth = 3, alpha = 0.5)\n",
    "        ax_show.plot(x_branch_2,y_branch_2, color = color, linestyle = lstyle, linewidth = 3, alpha = 0.5, label  = model_name)\n",
    "\n",
    "    return ax_show, curve1, curve2\n",
    "\n",
    "def plot_kite(jd, fig=None, ax=None):\n",
    "    if fig is None : \n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "    # Plot the initial polygons\n",
    "\n",
    "    _, curve1, curve2 = find_plot_contour(jd, ax_show = False, N_branch=81, offset_low = 1, offset_up=1, color = 'k', lstyle=\"--\", model_name = model_name+\" Summer\")\n",
    "\n",
    "    curve1_coords = np.array(curve1.coords)\n",
    "\n",
    "    km90_vertices = []\n",
    "    first_index = np.argmin(np.abs(curve1_coords[:,1]-20))\n",
    "    last_index = np.argmin(np.abs(curve1_coords[:,1]-40))\n",
    "    km90_vertices.extend(curve1_coords[first_index:last_index+1])  # Add a segment of curve1\n",
    "\n",
    "    km90_vertices.append((40, 40))  \n",
    "    km90_vertices.append((20, 20))  \n",
    "\n",
    "    km99_vertices = []\n",
    "    first_index = np.argmin(np.abs(curve1_coords[:,1]-40))\n",
    "    last_index = np.argmin(np.abs(curve1_coords[:,1]-81))\n",
    "    km99_vertices.extend(curve1_coords[first_index:last_index+1])  # Add a segment of curve1\n",
    "\n",
    "    km99_vertices.append((81, 81))  \n",
    "    km99_vertices.append((40, 40))  \n",
    "\n",
    "    curve1_coords = np.array(curve2.coords)\n",
    "\n",
    "    dd90_vertices = []\n",
    "    first_index = np.argmin(np.abs(curve1_coords[:,0]-20))\n",
    "    last_index = np.argmin(np.abs(curve1_coords[:,0]-40))\n",
    "    dd90_vertices.extend(curve1_coords[first_index:last_index+1])  # Add a segment of curve1\n",
    "\n",
    "    dd90_vertices.append((40, 40))  \n",
    "    dd90_vertices.append((20, 20))  \n",
    "\n",
    "    dd99_vertices = []\n",
    "    first_index = np.argmin(np.abs(curve1_coords[:,0]-40))\n",
    "    last_index = np.argmin(np.abs(curve1_coords[:,0]-81))\n",
    "    dd99_vertices.extend(curve1_coords[first_index:last_index+1])  # Add a segment of curve1\n",
    "\n",
    "    dd99_vertices.append((81, 81))  \n",
    "    dd99_vertices.append((40, 40))  \n",
    "\n",
    "    polygons = [\n",
    "        (km90_vertices, 'green', '90th km'),\n",
    "        (km99_vertices, 'lime', '99th km'),\n",
    "        (dd99_vertices, 'cyan', '99th dd'),\n",
    "        (dd90_vertices, 'blue', '90th dd')\n",
    "    ]\n",
    "\n",
    "    # Create a new patch with the constructed vertices\n",
    "    for vertices, color, label in polygons:\n",
    "        polygon = MplPolygon(vertices, closed=True, edgecolor=color, facecolor=color, linewidth=2, linestyle='--', alpha=0.2)\n",
    "        ax.add_patch(polygon)\n",
    "        \n",
    "        # Calculate approximate center for text placement\n",
    "        x_coords, y_coords = zip(*vertices)\n",
    "        center_x = np.mean(x_coords)\n",
    "        center_y = np.mean(y_coords)\n",
    "        \n",
    "        # Add text annotation\n",
    "        text = ax.text(center_x, center_y, label, color=color, fontsize=12, ha='center', va='center', weight='bold')\n",
    "        text.set_path_effects([path_effects.Stroke(linewidth=1.5, foreground='black'), path_effects.Normal()])\n",
    "    \n",
    "    return None\n",
    "\n",
    "def apply_mask(data, mask, mask_compat):\n",
    "    shape = np.shape(data)\n",
    "    mask = mask_compat & mask  # join mask\n",
    "    \n",
    "    fdata, fmask = data.reshape(-1), mask.reshape(-1)\n",
    "    fdata[~fmask] = np.nan\n",
    "    rdata = fdata.reshape(shape)\n",
    "    return rdata\n",
    "\n",
    "\n",
    "# Objective function to minimize\n",
    "def objective(coeff, data, data2):\n",
    "    # Reshape to 1D and remove NaNs\n",
    "    data_flat = data.reshape(-1)\n",
    "    data2_flat = data2.reshape(-1)\n",
    "\n",
    "    # Remove NaNs\n",
    "    valid_indices = ~np.isnan(data_flat) & ~np.isnan(data2_flat)\n",
    "    data_flat = data_flat[valid_indices]\n",
    "    data2_flat = data2_flat[valid_indices]\n",
    "\n",
    "    # Apply the coefficient to data2\n",
    "    scaled_data2 = coeff * data2_flat\n",
    "    \n",
    "    # Calculate the Frobenius norm\n",
    "    norm = np.linalg.norm(data_flat - scaled_data2)\n",
    "    return norm\n",
    "\n",
    "\n",
    "def compute_sigma_ratios(data_obs, data_list, jds): #sigma_density_obs_winter, sigma_density_winter_models\n",
    "    data = np.copy(data_obs.T)\n",
    "    n_models = len(data_list)\n",
    "    coeffs = np.zeros((n_models, 4)) #90th km, 99th km, 90th dd, 99th dd\n",
    "    norm_fits = np.zeros((n_models, 4))    #90th km, 99th km, 90th dd, 99th dd\n",
    "    n_points = np.zeros((n_models, 4))\n",
    "    \n",
    "    for i, sigma_density_model in enumerate(data_list):\n",
    "        jd = jds[i]\n",
    "        jd.make_mask()\n",
    "        data2 = np.copy(sigma_density_model.T) ## Here the first transpose !!! sneaky sneaky so don't fortget to transpose the mask as well \n",
    "\n",
    "        # Mask creation\n",
    "        mask_compat = (~np.isnan(data)) & (~np.isnan(data2))\n",
    "        mask_dd = jd.mask_coloc_ac_90.T\n",
    "        mask_km = jd.mask_coloc_c_90.T\n",
    "\n",
    "        # Initial coefficients\n",
    "        coeff_dd = 1\n",
    "        coeff_km = 1\n",
    "\n",
    "        # Apply masks\n",
    "        data_km_90th = apply_mask(data, mask_km, mask_compat)[20:40, 20:40]\n",
    "        data2_km_90th = apply_mask(data2, mask_km, mask_compat)[20:40, 20:40]\n",
    "\n",
    "        data_dd_90th = apply_mask(data, mask_dd, mask_compat)[20:40, 20:40]\n",
    "        data2_dd_90th = apply_mask(data2, mask_dd, mask_compat)[20:40, 20:40]\n",
    "\n",
    "        data_km_99th = apply_mask(data, mask_km, mask_compat)[40:, 40:]\n",
    "        data2_km_99th = apply_mask(data2, mask_km, mask_compat)[40:, 40:]\n",
    "\n",
    "        data_dd_99th = apply_mask(data, mask_dd, mask_compat)[40:, 40:]\n",
    "        data2_dd_99th = apply_mask(data2, mask_dd, mask_compat)[40:, 40:]\n",
    "\n",
    "\n",
    "        # Optimization for dd coefficient\n",
    "        result_dd_90th = minimize(objective, coeff_dd, args=(data_dd_90th, data2_dd_90th), method='L-BFGS-B', bounds=[(0, None)])\n",
    "        optimal_coeff_dd_90th = result_dd_90th.x[0]\n",
    "        result_dd_99th = minimize(objective, coeff_dd, args=(data_dd_99th, data2_dd_99th), method='L-BFGS-B', bounds=[(0, None)])\n",
    "        optimal_coeff_dd_99th = result_dd_99th.x[0]\n",
    "\n",
    "        # Optimization for km coefficient\n",
    "        result_km_90th = minimize(objective, coeff_km, args=(data_km_90th, data2_km_90th), method='L-BFGS-B', bounds=[(0, None)])\n",
    "        optimal_coeff_km_90th = result_km_90th.x[0]\n",
    "        result_km_99th = minimize(objective, coeff_km, args=(data_km_99th, data2_km_99th), method='L-BFGS-B', bounds=[(0, None)])\n",
    "        optimal_coeff_km_99th = result_km_99th.x[0]\n",
    "\n",
    "        # Add diagnostic print to check optimized norms\n",
    "        optimized_norm_dd_90th = objective(optimal_coeff_dd_90th, data_dd_90th, data2_dd_90th)\n",
    "        optimized_norm_km_90th = objective(optimal_coeff_km_90th, data_km_90th, data2_km_90th)\n",
    "        optimized_norm_dd_99th = objective(optimal_coeff_dd_99th, data_dd_99th, data2_dd_99th)\n",
    "        optimized_norm_km_99th = objective(optimal_coeff_km_99th, data_km_99th, data2_km_99th)\n",
    "        \n",
    "        coeffs[i, 0] = 1/optimal_coeff_km_90th\n",
    "        coeffs[i, 1] = 1/optimal_coeff_km_99th\n",
    "        coeffs[i, 2] = 1/optimal_coeff_dd_90th\n",
    "        coeffs[i, 3] = 1/optimal_coeff_dd_99th\n",
    "\n",
    "        round_int = 3\n",
    "\n",
    "        norm_fits[i, 0] = np.round(optimized_norm_km_90th, round_int)\n",
    "        norm_fits[i, 1] = np.round(optimized_norm_km_99th, round_int)\n",
    "        norm_fits[i, 2] = np.round(optimized_norm_dd_90th, round_int)\n",
    "        norm_fits[i, 3] = np.round(optimized_norm_dd_99th, round_int)\n",
    "        \n",
    "    return coeffs, norm_fits\n",
    "    \n",
    "### WINTER ###\n",
    "settings_path = 'settings/obs_winter_30d.yaml'\n",
    "hdlr = handler.Handler(settings_path)\n",
    "cs = casestudy.CaseStudy(hdlr, overwrite = False ,verbose = False)\n",
    "gr = grid.Grid(cs, fast = True, overwrite= False, verbose_steps = False, verbose = False)\n",
    "st = storm_tracker.StormTracker(gr, label_var_id = \"MCS_label\", overwrite_storms = False, overwrite = False)\n",
    "jd = joint_distrib.JointDistribution(gr, None, var_id_1 = \"mean_unweighted_Prec\", var_id_2 = \"cond_alpha_\"+alpha+\"_Prec\", nbpd = nbpd,  nd=nd, overwrite = True, dist_mask = False)\n",
    "jd_ocean = joint_distrib.JointDistribution(gr, None, var_id_1 = \"mean_unweighted_Prec\", var_id_2 = \"cond_alpha_\"+alpha+\"_Prec\", nbpd = nbpd,  nd=nd, overwrite = True, dist_mask = \"ocean\")\n",
    "jd_land = joint_distrib.JointDistribution(gr, None, var_id_1 = \"mean_unweighted_Prec\", var_id_2 = \"cond_alpha_\"+alpha+\"_Prec\", nbpd = nbpd,  nd=nd, overwrite = True, dist_mask = \"land\")\n",
    "\n",
    "\n",
    "settings_paths = [\"settings/arpege_winter_30d.yaml\", \"settings/ifs_winter_30d.yaml\", \"settings/mpas_winter_30d.yaml\", \"settings/screamv1_winter_30d.yaml\", \"settings/sam_winter_30d.yaml\", \"settings/um_winter_30d.yaml\", \"settings/xshield_winter_30d.yaml\", \"settings/geos_winter_30d.yaml\", \"settings/grist_winter_30d.yaml\",                ]\n",
    "\n",
    "hdlrs = [handler.Handler(settings_path) for settings_path in settings_paths]\n",
    "css = [casestudy.CaseStudy(hdlr, overwrite = False ,verbose = False) for hdlr in hdlrs]\n",
    "grs = [grid.Grid(cs, fast = True, overwrite= False, verbose_steps = False, verbose = False) for cs in css]\n",
    "jds_winter = [joint_distrib.JointDistribution(gr, None, var_id_1 = \"mean_unweighted_Prec\", var_id_2 = \"cond_alpha_\"+alpha+\"_Prec\", \n",
    "        nbpd = nbpd,  nd=nd, overwrite = True, dist_mask = False) for gr in grs]\n",
    "jds_winter_ocean = [joint_distrib.JointDistribution(gr, None, var_id_1 = \"mean_unweighted_Prec\", var_id_2 = \"cond_alpha_\"+alpha+\"_Prec\", \n",
    "        nbpd = nbpd,  nd=nd, overwrite = True, dist_mask = \"ocean\") for gr in grs]\n",
    "jds_winter_land = [joint_distrib.JointDistribution(gr, None, var_id_1 = \"mean_unweighted_Prec\", var_id_2 = \"cond_alpha_\"+alpha+\"_Prec\", \n",
    "        nbpd = nbpd,  nd=nd, overwrite = True, dist_mask = \"land\") for gr in grs]\n",
    "\n",
    "sigma_density_winter_ocean_models = []\n",
    "sigma_density_winter_land_models = []\n",
    "\n",
    "if same_rank_bool : \n",
    "    _, _, _, sigma_density_obs_winter_ocean = jd.plot_var_id_func_over_jdist('Prec', func = 'Sigma_cond_alpha_'+alpha, mask = \"ocean\", fig = False)\n",
    "    _, _, _, sigma_density_obs_winter_land = jd.plot_var_id_func_over_jdist('Prec', func = 'Sigma_cond_alpha_'+alpha, mask = \"land\", fig = False) \n",
    "    for jd in jds_winter: \n",
    "        _, _, _, sigma_density_model_winter_ocean = jd.plot_var_id_func_over_jdist('Prec', func = 'Sigma_cond_alpha_'+alpha, mask = \"ocean\", fig = False) \n",
    "        _, _, _, sigma_density_model_winter_land = jd.plot_var_id_func_over_jdist('Prec', func = 'Sigma_cond_alpha_'+alpha, mask = \"land\", fig = False) \n",
    "\n",
    "        sigma_density_winter_ocean_models.append(sigma_density_model_winter_ocean)\n",
    "        sigma_density_winter_land_models.append(sigma_density_model_winter_land)\n",
    "else : \n",
    "    _, _, _, sigma_density_obs_winter_ocean = jd_ocean.plot_var_id_func_over_jdist('Prec', func = 'Sigma_cond_alpha_'+alpha, mask = \"ocean\", fig = False)\n",
    "    _, _, _, sigma_density_obs_winter_land = jd_land.plot_var_id_func_over_jdist('Prec', func = 'Sigma_cond_alpha_'+alpha, mask = \"land\", fig = False) \n",
    "    for jd_ocean, jd_land in zip(jds_winter_ocean, jds_winter_land):\n",
    "        _, _, _, sigma_density_model_winter_ocean = jd_ocean.plot_var_id_func_over_jdist('Prec', func = 'Sigma_cond_alpha_'+alpha, mask = \"ocean\", fig = False) \n",
    "        _, _, _, sigma_density_model_winter_land = jd_land.plot_var_id_func_over_jdist('Prec', func = 'Sigma_cond_alpha_'+alpha, mask = \"land\", fig = False) \n",
    "\n",
    "        sigma_density_winter_ocean_models.append(sigma_density_model_winter_ocean)\n",
    "        sigma_density_winter_land_models.append(sigma_density_model_winter_land)\n",
    "\n",
    "### SUMMER ###\n",
    "settings_paths = [\"settings/arpege_summer_30d.yaml\", \"settings/ifs_summer_30d.yaml\" , \"settings/mpas_summer_30d.yaml\", \"settings/screamv1_summer_30d.yaml\", \"settings/sam_summer_30d.yaml\", \"settings/um_summer_30d.yaml\", \"settings/fv3_summer_30d.yaml\",  \"settings/nicam_summer_30d.yaml\"]\n",
    "\n",
    "hdlrs = [handler.Handler(settings_path) for settings_path in settings_paths]\n",
    "css = [casestudy.CaseStudy(hdlr, overwrite = False ,verbose = False) for hdlr in hdlrs]\n",
    "grs = [grid.Grid(cs, fast = True, overwrite = False, verbose_steps = False, verbose = False) for cs in css]\n",
    "jds_summer = [joint_distrib.JointDistribution(gr, None, var_id_1 = \"mean_unweighted_Prec\", var_id_2 = \"cond_alpha_\"+alpha+\"_Prec\", \n",
    "        nbpd = nbpd,  nd=nd, overwrite = True, dist_mask = False) for gr in grs]\n",
    "jds_summer_ocean = [joint_distrib.JointDistribution(gr, None, var_id_1 = \"mean_unweighted_Prec\", var_id_2 = \"cond_alpha_\"+alpha+\"_Prec\", \n",
    "        nbpd = nbpd,  nd=nd, overwrite = True, dist_mask = \"ocean\") for gr in grs]\n",
    "jds_summer_land = [joint_distrib.JointDistribution(gr, None, var_id_1 = \"mean_unweighted_Prec\", var_id_2 = \"cond_alpha_\"+alpha+\"_Prec\", \n",
    "        nbpd = nbpd,  nd=nd, overwrite = True, dist_mask = \"land\") for gr in grs]\n",
    "\n",
    "settings_path = 'settings/obs_summer_30d.yaml'\n",
    "hdlr = handler.Handler(settings_path)\n",
    "cs = casestudy.CaseStudy(hdlr, overwrite = False ,verbose = False)\n",
    "gr = grid.Grid(cs, fast = True, overwrite= False, verbose_steps = False, verbose = False)\n",
    "st = storm_tracker.StormTracker(gr, label_var_id = \"MCS_label\", overwrite_storms = False, overwrite = False)\n",
    "jd = joint_distrib.JointDistribution(gr, None, var_id_1 = \"mean_unweighted_Prec\", var_id_2 = \"cond_alpha_\"+alpha+\"_Prec\",nbpd = nbpd,  nd=nd, overwrite = True, dist_mask = False)\n",
    "jd_ocean = joint_distrib.JointDistribution(gr, None, var_id_1 = \"mean_unweighted_Prec\", var_id_2 = \"cond_alpha_\"+alpha+\"_Prec\",nbpd = nbpd,  nd=nd, overwrite = True, dist_mask = \"ocean\")\n",
    "jd_land = joint_distrib.JointDistribution(gr, None, var_id_1 = \"mean_unweighted_Prec\", var_id_2 = \"cond_alpha_\"+alpha+\"_Prec\",nbpd = nbpd,  nd=nd, overwrite = True, dist_mask = \"land\")\n",
    "\n",
    "sigma_density_summer_ocean_models = []\n",
    "sigma_density_summer_land_models  = []\n",
    "\n",
    "if same_rank_bool : \n",
    "    _, _, _, sigma_density_obs_summer_ocean = jd.plot_var_id_func_over_jdist('Prec', func = 'Sigma_cond_alpha_'+alpha, mask = \"ocean\", fig = False) \n",
    "    _, _, _, sigma_density_obs_summer_land  = jd.plot_var_id_func_over_jdist('Prec', func = 'Sigma_cond_alpha_'+alpha, mask = \"land\", fig = False)\n",
    "    for jd in jds_summer: \n",
    "        _, _, _, sigma_density_model_summer_ocean = jd.plot_var_id_func_over_jdist('Prec', func = 'Sigma_cond_alpha_'+alpha, mask = \"ocean\", fig = False)\n",
    "        _, _, _, sigma_density_model_summer_land  = jd.plot_var_id_func_over_jdist('Prec', func = 'Sigma_cond_alpha_'+alpha, mask = \"land\", fig = False)\n",
    "        sigma_density_summer_ocean_models.append(sigma_density_model_summer_ocean)\n",
    "        sigma_density_summer_land_models.append(sigma_density_model_summer_land)\n",
    "else : \n",
    "    _, _, _, sigma_density_obs_summer_ocean = jd_ocean.plot_var_id_func_over_jdist('Prec', func = 'Sigma_cond_alpha_'+alpha, mask = \"ocean\", fig = False) \n",
    "    _, _, _, sigma_density_obs_summer_land  = jd_land.plot_var_id_func_over_jdist('Prec', func = 'Sigma_cond_alpha_'+alpha, mask = \"land\", fig = False)\n",
    "    for jd_ocean, jd_land in zip(jds_summer_ocean, jds_summer_land): \n",
    "        _, _, _, sigma_density_model_summer_ocean = jd_ocean.plot_var_id_func_over_jdist('Prec', func = 'Sigma_cond_alpha_'+alpha, mask = \"ocean\", fig = False)\n",
    "        _, _, _, sigma_density_model_summer_land  = jd_land.plot_var_id_func_over_jdist('Prec', func = 'Sigma_cond_alpha_'+alpha, mask = \"land\", fig = False)\n",
    "        sigma_density_summer_ocean_models.append(sigma_density_model_summer_ocean)\n",
    "        sigma_density_summer_land_models.append(sigma_density_model_summer_land)\n",
    "\n",
    "\n",
    "## Compute\n",
    "coeffs_wo, norm_fits_wo = compute_sigma_ratios(sigma_density_obs_winter_ocean, sigma_density_winter_ocean_models, jds_winter)\n",
    "coeffs_wl, norm_fits_wl = compute_sigma_ratios(sigma_density_obs_winter_land, sigma_density_winter_land_models, jds_winter)\n",
    "coeffs_so, norm_fits_so = compute_sigma_ratios(sigma_density_obs_summer_ocean, sigma_density_summer_ocean_models, jds_summer)\n",
    "coeffs_sl, norm_fits_sl = compute_sigma_ratios(sigma_density_obs_summer_land, sigma_density_summer_land_models, jds_summer)\n",
    "\n",
    "# Plot colors per models\n",
    "num_colors = 10\n",
    "cmap = plt.get_cmap('hsv')\n",
    "color_values = np.linspace(0, 0.9, num_colors)\n",
    "model_colors = [cmap(value) for value in color_values]\n",
    "model_colors[2] = (1.0, 1.0, 0.0, 1.0) ## yellow\n",
    "model_colors[3] = (0.6, 1.0, 0.0, 1.0) ## greenish yellow\n",
    "\n",
    "# Create subplots with 3 rows and 2 columns\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12.5, 16))\n",
    "\n",
    "##Preshow \n",
    "settings_path = 'settings/obs_winter_30d.yaml'\n",
    "hdlr = handler.Handler(settings_path)\n",
    "cs = casestudy.CaseStudy(hdlr, overwrite = False ,verbose = False)\n",
    "gr = grid.Grid(cs, fast = True, overwrite= False, verbose_steps = False, verbose = False)\n",
    "st = storm_tracker.StormTracker(gr, label_var_id = \"MCS_label\", overwrite_storms = False, overwrite = False)\n",
    "jd_winter = joint_distrib.JointDistribution(gr, None, var_id_1 = \"mean_unweighted_Prec\", var_id_2 = \"cond_alpha_75_Prec\", nbpd = 20,  nd=4, overwrite = True, dist_mask = \"all\")\n",
    "\n",
    "settings_path = 'settings/obs_summer_30d.yaml'\n",
    "hdlr = handler.Handler(settings_path)\n",
    "cs = casestudy.CaseStudy(hdlr, overwrite = False ,verbose = False)\n",
    "gr = grid.Grid(cs, fast = True, overwrite= False, verbose_steps = False, verbose = False)\n",
    "st = storm_tracker.StormTracker(gr, label_var_id = \"MCS_label\", overwrite_storms = False, overwrite = False)\n",
    "jd_summer = joint_distrib.JointDistribution(gr, None, var_id_1 = \"mean_unweighted_Prec\", var_id_2 = \"cond_alpha_75_Prec\", nbpd = 20,  nd=4, overwrite = True, dist_mask = \"all\")\n",
    "\n",
    "\n",
    "## left one\n",
    "model_name = jd_winter.settings[\"MODEL\"][:-7]\n",
    "cmap = sns.color_palette(\"icefire\", as_cmap=True)\n",
    "values_and_boundaries = np.arange(0, 0.1+0.002, 0.002)\n",
    "values = values_and_boundaries\n",
    "boundaries  = values_and_boundaries\n",
    "norm = mpl.colors.BoundaryNorm(boundaries, cmap.N)\n",
    "\n",
    "ax, cb, ax_show_, sigma_density_obs_winter = jd_winter.plot_var_id_func_over_jdist('Prec', func = 'Sigma_cond_alpha_75', title=model_name, mask = \"all\", cmap = cmap, norm = norm, fig = fig, ax = axes[0,0])\n",
    "_, _, _, sigma_density_obs_summer = jd_summer.plot_var_id_func_over_jdist('Prec', func = 'Sigma_cond_alpha_75', title=model_name, mask = \"all\", cmap = cmap, norm = norm, fig = False)\n",
    "axes[0,0].set_ylabel(r\"$P_{0.25}$\")\n",
    "axes[0,0].set_xlabel(r\"$P$\")\n",
    "cb.set_label(r\"$\\sigma_{0.25}$\", fontsize=12)\n",
    "axes[0,0].set_title(\"Winter Observations $\\sigma_{0.25}$\")\n",
    "\n",
    "## Sigma ratio for explanation\n",
    "cmap = sns.color_palette(\"RdBu\", as_cmap=True)\n",
    "values_and_boundaries = np.arange(0.5, 1.55, 0.05)\n",
    "values = values_and_boundaries\n",
    "boundaries  = values_and_boundaries\n",
    "norm = mpl.colors.BoundaryNorm(boundaries, cmap.N)\n",
    "\n",
    "obs_season_ratio_sigma_75 = sigma_density_obs_winter/sigma_density_obs_summer\n",
    "ax, cb, ax_show, sigma_density_obs_summer = jd_summer.plot_var_id_func_over_jdist('Prec', func = 'Sigma_cond_alpha_75', title=model_name, mask = \"all\", cmap = cmap, norm = norm, fig = fig, ax = axes[0,1], density=obs_season_ratio_sigma_75)\n",
    "axes[0,1].set_ylabel(r\"$P_{0.25}$\")\n",
    "axes[0,1].set_xlabel(r\"$P$\")\n",
    "# cb.set_label()\n",
    "cb.ax.set_ylabel(r'$\\frac{\\sigma^{Winter}_{0.25}}{\\sigma^{Summer}_{0.25}}$', fontsize=13, rotation = 0, labelpad = 20)\n",
    "\n",
    "title = r\"Ratio of Winter $\\sigma_{0.25}$ over Summer $\\sigma_{0.25}$\"\n",
    "axes[0,1].set_title(title)\n",
    "plot_kite(jd_summer, fig, ax_show)\n",
    "\n",
    "\n",
    "# Titles for subplots\n",
    "axes[1, 0].set_title(r'Oceanic Winter ratio of model $\\sigma_{0.25}$ over Observations $\\sigma_{0.25}$')\n",
    "axes[2, 0].set_title(r'Continental Winter ratio of model $\\sigma_{0.25}$ over Observations $\\sigma_{0.25}$')\n",
    "axes[1, 1].set_title(r'Oceanic Summer ratio of model $\\sigma_{0.25}$ over Observations $\\sigma_{0.25}$')\n",
    "axes[2, 1].set_title(r'Continental Summer ratio of model $\\sigma_{0.25}$ over Observations $\\sigma_{0.25}$')\n",
    "\n",
    "# Loop through the index i\n",
    "for i in np.arange(4):\n",
    "    # Loop for winter coefficients\n",
    "    for j, jd_winter in enumerate(jds_winter):\n",
    "        model_name = jd_winter.name.split(\"_\")[0]\n",
    "        color = model_colors[j]\n",
    "        \n",
    "        if i == 0:\n",
    "            axes[1, 0].scatter([i], coeffs_wo[j, i], color=color, label=model_name)\n",
    "            axes[1, 0].plot([i, i+1], [coeffs_wo[j, i], coeffs_wo[j, i+1]], color = color, linestyle = \"--\", alpha = 0.8)\n",
    "            \n",
    "            axes[2, 0].scatter([i], coeffs_wl[j, i], color=color, label=model_name)\n",
    "            axes[2, 0].plot([i, i+1], [coeffs_wl[j, i], coeffs_wl[j, i+1]], color = color, linestyle = \"--\", alpha = 0.8)\n",
    "        else:\n",
    "            # Scatter plot for winter coefficients without labels\n",
    "            axes[1, 0].scatter([i], coeffs_wo[j, i], color=color)\n",
    "            axes[2, 0].scatter([i], coeffs_wl[j, i], color=color)\n",
    "\n",
    "            if i ==2 : \n",
    "                axes[1, 0].plot([i, i+1], [coeffs_wo[j, i], coeffs_wo[j, i+1]], color = color, linestyle = \"--\", alpha = 0.8)\n",
    "                axes[2, 0].plot([i, i+1], [coeffs_wl[j, i], coeffs_wl[j, i+1]], color = color, linestyle = \"--\", alpha = 0.8)\n",
    "\n",
    "    # Loop for summer coefficients\n",
    "    for j, jd_summer in enumerate(jds_summer):\n",
    "        model_name_summer = jd_summer.name.split(\"_\")[0]\n",
    "        color = model_colors[j]\n",
    "        if model_name_summer == \"NICAM\":\n",
    "            color = model_colors[9]\n",
    "        if i == 0:          \n",
    "            # Scatter plot for summer coefficients with labels\n",
    "            axes[1, 1].scatter([i], coeffs_so[j, i], color=color, label=model_name_summer)\n",
    "            axes[1, 1].plot([i, i+1], [coeffs_so[j, i], coeffs_so[j, i+1]], color = color, linestyle = \"--\", alpha = 0.8)\n",
    "\n",
    "            axes[2, 1].scatter([i], coeffs_sl[j, i], color=color, label=model_name_summer)\n",
    "            axes[2, 1].plot([i, i+1], [coeffs_sl[j, i], coeffs_sl[j, i+1]], color = color, linestyle = \"--\", alpha = 0.8)\n",
    "            \n",
    "        else:\n",
    "            # Scatter plot for summer coefficients without labels\n",
    "            axes[1, 1].scatter([i], coeffs_so[j, i], color=color)\n",
    "            axes[2, 1].scatter([i], coeffs_sl[j, i], color=color)\n",
    "            if i == 2 :\n",
    "                axes[1, 1].plot([i, i+1], [coeffs_so[j, i], coeffs_so[j, i+1]], color = color, linestyle = \"--\", alpha = 0.8)\n",
    "                axes[2, 1].plot([i, i+1], [coeffs_sl[j, i], coeffs_sl[j, i+1]], color = color, linestyle = \"--\", alpha = 0.8)\n",
    "\n",
    "# Set x-axis labels\n",
    "x_labels = ['90th km', '99th km', '90th dd', '99th dd']\n",
    "for ax in axes.flatten()[2:]:\n",
    "    ax.set_xticks(np.arange(4))\n",
    "    ax.set_xticklabels(x_labels, rotation=30, fontsize=10)\n",
    "    ax.set_xbound(-2, 3.5)\n",
    "    ax.set_ybound(0.01, 0.99)\n",
    "    ax.grid(True, which='both', axis='y', linestyle='--', linewidth=0.7)\n",
    "\n",
    "    # Add legends\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    ax.legend(loc=\"upper left\")\n",
    "\n",
    "# Set the overall title for the figure\n",
    "# fig.suptitle(r\"Ratio of 'surface in extreme phase space' of models $\\sigma_{0.15}$ over $\\sigma_{0.15}$ obs\")\n",
    "\n",
    "# Adjust layout to prevent overlapping of elements\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(fig_path, dpi = 300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyHD)",
   "language": "python",
   "name": "pyhd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
